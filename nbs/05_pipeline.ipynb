{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp mario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Pipeline\n",
    "\n",
    "<br>\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  4.32rows/s]\n"
     ]
    }
   ],
   "source": [
    "#exports\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from satip import eumetsat, reproj, io, gcp_helpers\n",
    "from dagster import execute_pipeline, pipeline, solid, Field\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import dotenv\n",
    "import warnings\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Log Cleaning\n",
    "\n",
    "We'll suppress some errors/warnings to make the logs easier to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "warnings.filterwarnings('ignore', message='divide by zero encountered in true_divide')\n",
    "warnings.filterwarnings('ignore', message='invalid value encountered in sin')\n",
    "warnings.filterwarnings('ignore', message='invalid value encountered in cos')\n",
    "warnings.filterwarnings('ignore', message='invalid value encountered in subtract')\n",
    "warnings.filterwarnings('ignore', message='You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Dagster Pipeline\n",
    "\n",
    "We're now going to combine these steps into a pipeline using `dagster`, first we'll create the individual components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "@solid()\n",
    "def download_eumetsat_files(context, env_vars_fp: str, data_dir: str, metadata_db_fp: str, debug_fp: str, table_id: str, project_id: str, start_date: str='', end_date: str='', max_mins: int=60):\n",
    "    _ = dotenv.load_dotenv(env_vars_fp)\n",
    "    \n",
    "    if start_date == '':\n",
    "        sql_query = f'select * from {table_id} where result_time = (select max(result_time) from {table_id})'\n",
    "        \n",
    "        latest_saved_date = gcp_helpers.query(sql_query, project_id)['result_time'].iloc[0].tz_localize(None)\n",
    "        earliest_start_date = pd.Timestamp.now() - pd.Timedelta(max_mins, unit='minutes')\n",
    "        \n",
    "        start_date = max(earliest_start_date, latest_saved_date).strftime('%Y-%m-%d %H:%M')\n",
    "        \n",
    "    if end_date == '':\n",
    "        end_date = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')\n",
    "        \n",
    "    context.log.info(f'Querying data between {start_date} - {end_date}')\n",
    "\n",
    "    dm = eumetsat.DownloadManager(os.environ.get('USER_KEY'), os.environ.get('USER_SECRET'), data_dir, metadata_db_fp, debug_fp, slack_webhook_url=os.environ.get('SLACK_WEBHOOK_URL'), slack_id=os.environ.get('SLACK_ID'))\n",
    "    df_new_metadata = dm.download_date_range(start_date, end_date)\n",
    "\n",
    "    if df_new_metadata is None:\n",
    "        df_new_metadata = pd.DataFrame(columns=['result_time', 'file_name'])\n",
    "    else:\n",
    "        df_new_metadata = df_new_metadata.iloc[1:] # the first entry is the last one we downloaded\n",
    "        \n",
    "    return df_new_metadata\n",
    "\n",
    "@solid()\n",
    "def df_metadata_to_dt_to_fp_map(_, df_new_metadata, data_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    Here we'll then identify downloaded files in \n",
    "    the metadata dataframe and return a mapping\n",
    "    between datetimes and filenames\n",
    "    \"\"\"\n",
    "    \n",
    "    datetime_to_filename = (df_new_metadata\n",
    "                            .set_index('result_time')\n",
    "                            ['file_name']\n",
    "                            .drop_duplicates()\n",
    "                            .to_dict()\n",
    "                           )\n",
    "\n",
    "    datetime_to_filepath = {\n",
    "        datetime: f\"{data_dir}/{filename}.nat\" \n",
    "        for datetime, filename \n",
    "        in datetime_to_filename.items()\n",
    "        if filename != {}\n",
    "    }\n",
    "    \n",
    "    return datetime_to_filepath\n",
    "\n",
    "@solid()\n",
    "def reproject_datasets(_, datetime_to_filepath: dict, new_coords_fp: str, new_grid_fp: str):\n",
    "    reprojector = reproj.Reprojector(new_coords_fp, new_grid_fp)\n",
    "\n",
    "    reprojected_dss = [\n",
    "        (reprojector\n",
    "         .reproject(filepath, reproj_library='pyresample')\n",
    "         .pipe(io.add_constant_coord_to_da, 'time', pd.to_datetime(datetime))\n",
    "        )\n",
    "        for datetime, filepath \n",
    "        in datetime_to_filepath.items()\n",
    "    ]\n",
    "\n",
    "    if len(reprojected_dss) > 0:\n",
    "        ds_combined_reproj = xr.concat(reprojected_dss, 'time', coords='all', data_vars='all')\n",
    "        return ds_combined_reproj\n",
    "    else:\n",
    "        return xr.Dataset()\n",
    "\n",
    "@solid()\n",
    "def compress_and_save_datasets(_, ds_combined_reproj, zarr_bucket: str, var_name: str='stacked_eumetsat_data'):\n",
    "    # Handle case where no new data exists\n",
    "    if len(ds_combined_reproj.dims) == 0:\n",
    "        print(\"compress_and_save_datasets: No new data to save to zarr\")\n",
    "        return\n",
    "    \n",
    "    # Compressing the datasets\n",
    "    compressor = io.Compressor()\n",
    "\n",
    "    var_name = var_name\n",
    "    da_compressed = compressor.compress(ds_combined_reproj[var_name])\n",
    "\n",
    "    # Saving to Zarr\n",
    "    ds_compressed = io.save_da_to_zarr(da_compressed, zarr_bucket)\n",
    "    \n",
    "    return ds_compressed\n",
    "\n",
    "@solid()\n",
    "def save_metadata(context, ds_combined_compressed, df_new_metadata, table_id: str, project_id: str):\n",
    "    if ds_combined_compressed is not None:\n",
    "        if df_new_metadata.shape[0] > 0:\n",
    "            gcp_helpers.write_metadata_to_gcp(df_new_metadata, table_id, project_id, append=True)\n",
    "            context.log.info(f'{df_new_metadata.shape[0]} new metadata entries were added')\n",
    "        else:\n",
    "            context.log.info('No metadata was available to be added')\n",
    "            \n",
    "    return True\n",
    "\n",
    "@solid()\n",
    "def compress_export_then_delete_raw(context, ds_combined_compressed, data_dir: str, compressed_dir: str, BUCKET_NAME: str='solar-pv-nowcasting-data', PREFIX: str='satellite/EUMETSAT/SEVIRI_RSS/native/', ready_to_delete: bool=True):\n",
    "    if ready_to_delete == True:\n",
    "        eumetsat.compress_downloaded_files(data_dir=data_dir, compressed_dir=compressed_dir, log=context.log)\n",
    "        eumetsat.upload_compressed_files(compressed_dir, BUCKET_NAME=BUCKET_NAME, PREFIX=PREFIX, log=None)\n",
    "        \n",
    "        for dir_ in [data_dir, compressed_dir]:\n",
    "            context.log.info(f'Removing directory {dir_}')\n",
    "            shutil.rmtree(dir_)\n",
    "            os.mkdir(dir_) # recreate empty folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Then we'll combine them in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "@pipeline\n",
    "def download_latest_data_pipeline(): \n",
    "    df_new_metadata = download_eumetsat_files()\n",
    "    datetime_to_filepath = df_metadata_to_dt_to_fp_map(df_new_metadata)\n",
    "    ds_combined_reproj = reproject_datasets(datetime_to_filepath)\n",
    "    ds_combined_compressed = compress_and_save_datasets(ds_combined_reproj)\n",
    "    \n",
    "    ready_to_delete = save_metadata(ds_combined_compressed, df_new_metadata)\n",
    "    compress_export_then_delete_raw(ready_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Which we'll now run a test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Starting initialization of resources [asset_store].\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Finished initialization of resources [asset_store].\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - PIPELINE_START - Started execution of pipeline \"download_latest_data_pipeline\".\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Executing steps in process (pid: 28895)\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_START - Started execution of step \"download_eumetsat_files.compute\".\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"env_vars_fp\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"metadata_db_fp\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"debug_fp\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"table_id\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"project_id\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"start_date\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"end_date\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:09 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_INPUT - Got input \"max_mins\" of type \"Int\". (Type check passed).\n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  4.29rows/s]\n",
      "2021-02-25 18:11:11 - dagster - INFO - system - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - download_eumetsat_files.compute - Querying data between 2021-02-25 17:11 - 2021-02-25 18:11\n",
      "2021-02-25 18:11:11,425 - INFO - ********** Download Manager Initialised **************\n",
      "2021-02-25 18:11:11,888 - INFO - 0 files queried, 0 found in ../data/raw, 0 to download.\n",
      "2021-02-25 18:11:11,890 - INFO - No files will be downloaded. Set DownloadManager bucket_name argument for local download\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - download_eumetsat_files.compute - STEP_SUCCESS - Finished execution of step \"download_eumetsat_files.compute\" in 2.21s.\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_START - Started execution of step \"df_metadata_to_dt_to_fp_map.compute\".\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df_new_metadata in memory object store using pickle.\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_INPUT - Got input \"df_new_metadata\" of type \"Any\". (Type check passed).\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_OUTPUT - Yielded output \"result\" of type \"dict\". (Type check passed).\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - df_metadata_to_dt_to_fp_map.compute - STEP_SUCCESS - Finished execution of step \"df_metadata_to_dt_to_fp_map.compute\" in 5.63ms.\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_START - Started execution of step \"reproject_datasets.compute\".\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input datetime_to_filepath in memory object store using pickle.\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_INPUT - Got input \"datetime_to_filepath\" of type \"dict\". (Type check passed).\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_INPUT - Got input \"new_coords_fp\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:11 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_INPUT - Got input \"new_grid_fp\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - reproject_datasets.compute - STEP_SUCCESS - Finished execution of step \"reproject_datasets.compute\" in 962ms.\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_START - Started execution of step \"compress_and_save_datasets.compute\".\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_reproj in memory object store using pickle.\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"ds_combined_reproj\" of type \"Any\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"zarr_bucket\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_INPUT - Got input \"var_name\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_and_save_datasets.compute - STEP_SUCCESS - Finished execution of step \"compress_and_save_datasets.compute\" in 1.3ms.\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_START - Started execution of step \"save_metadata.compute\".\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_compressed in memory object store using pickle.\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df_new_metadata in memory object store using pickle.\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"ds_combined_compressed\" of type \"Any\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"df_new_metadata\" of type \"Any\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"table_id\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_INPUT - Got input \"project_id\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - save_metadata.compute - STEP_SUCCESS - Finished execution of step \"save_metadata.compute\" in 1.23ms.\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_START - Started execution of step \"compress_export_then_delete_raw.compute\".\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input ds_combined_compressed in memory object store using pickle.\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"ds_combined_compressed\" of type \"Any\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"data_dir\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"compressed_dir\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"BUCKET_NAME\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"PREFIX\" of type \"String\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_INPUT - Got input \"ready_to_delete\" of type \"Bool\". (Type check passed).\n",
      "2021-02-25 18:11:12 - dagster - INFO - system - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - compress_export_then_delete_raw.compute - Found 0 native files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 native files.\n",
      "Moved and compressed 0 files to ../data/compressed\n",
      "File /Users/laurence/code/Satip/nbs/../data/compressed/2020/10/01/12/04/MSG3-SEVI-MSG15-0100-NA-20201001120415.953000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/10/01/12/04/MSG3-SEVI-MSG15-0100-NA-20201001120415.953000000Z-NA.nat.bz2.\n",
      "File /Users/laurence/code/Satip/nbs/../data/compressed/2020/10/01/12/09/MSG3-SEVI-MSG15-0100-NA-20201001120915.775000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/10/01/12/09/MSG3-SEVI-MSG15-0100-NA-20201001120915.775000000Z-NA.nat.bz2.\n",
      "File /Users/laurence/code/Satip/nbs/../data/compressed/2020/01/01/00/04/MSG3-SEVI-MSG15-0100-NA-20200101000414.102000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/01/01/00/04/MSG3-SEVI-MSG15-0100-NA-20200101000414.102000000Z-NA.nat.bz2.\n",
      "File /Users/laurence/code/Satip/nbs/../data/compressed/2020/01/01/00/09/MSG3-SEVI-MSG15-0100-NA-20200101000915.215000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/01/01/00/09/MSG3-SEVI-MSG15-0100-NA-20200101000915.215000000Z-NA.nat.bz2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-25 18:11:58 - dagster - INFO - system - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - compress_export_then_delete_raw.compute - File path ../data/compressed/2020 was not removed.\n",
      "2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - compress_export_then_delete_raw.compute - STEP_SUCCESS - Finished execution of step \"compress_export_then_delete_raw.compute\" in 45.46s.\n",
      "2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - ENGINE_EVENT - Finished steps in process (pid: 28895) in 48.68s\n",
      "2021-02-25 18:11:58 - dagster - DEBUG - download_latest_data_pipeline - 15272dda-37f5-4b7a-b66c-71ab58f63bd8 - 28895 - PIPELINE_SUCCESS - Finished execution of pipeline \"download_latest_data_pipeline\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/laurence/code/Satip/nbs/../data/compressed/2020/01/01/00/14/MSG3-SEVI-MSG15-0100-NA-20200101001416.328000000Z-NA.nat.bz2 uploaded to satellite/EUMETSAT/SEVIRI_RSS/native/2020/01/01/00/14/MSG3-SEVI-MSG15-0100-NA-20200101001416.328000000Z-NA.nat.bz2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dagster.core.execution.results.PipelineExecutionResult at 0x7fc94e591df0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_config = {\n",
    "    'solids': {\n",
    "        'download_eumetsat_files': {\n",
    "            'inputs': {\n",
    "                'env_vars_fp': \"../.env\",\n",
    "                'data_dir': \"../data/raw\",\n",
    "                'metadata_db_fp': \"../data/EUMETSAT_metadata.db\",\n",
    "                'debug_fp': \"../logs/EUMETSAT_download.txt\",\n",
    "                'table_id': \"eumetsat.metadata\",\n",
    "                'project_id': \"solar-pv-nowcasting\",\n",
    "                'start_date': \"\",\n",
    "                'end_date': \"\"\n",
    "            },\n",
    "        },\n",
    "        'df_metadata_to_dt_to_fp_map': {\n",
    "            'inputs': {\n",
    "                'data_dir': \"../data/raw\"\n",
    "            }\n",
    "        },\n",
    "        'reproject_datasets': {\n",
    "            'inputs': {\n",
    "                'new_coords_fp': \"../data/intermediate/reproj_coords_TM_4km.csv\",\n",
    "                'new_grid_fp': \"../data/intermediate/new_grid_4km_TM.json\"\n",
    "            }\n",
    "        },\n",
    "        'compress_and_save_datasets': {\n",
    "            'inputs': {\n",
    "                'zarr_bucket': \"solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/full_extent_TM_int16\",\n",
    "                'var_name': \"stacked_eumetsat_data\"\n",
    "            }\n",
    "        },\n",
    "        'save_metadata': {\n",
    "            'inputs': {\n",
    "                'table_id': \"eumetsat.metadata\",\n",
    "                'project_id': \"solar-pv-nowcasting\"\n",
    "            },\n",
    "        },\n",
    "        'compress_export_then_delete_raw': {\n",
    "            'inputs': {\n",
    "                'data_dir': \"../data/raw\",\n",
    "                'compressed_dir': \"../data/compressed\",\n",
    "                'BUCKET_NAME': \"solar-pv-nowcasting-data\",\n",
    "                'PREFIX': \"satellite/EUMETSAT/SEVIRI_RSS/native/\",\n",
    "                'ready_to_delete': True\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "execute_pipeline(download_latest_data_pipeline, run_config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 05_pipeline.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script('05_pipeline.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
